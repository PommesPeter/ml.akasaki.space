<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs | 工具箱的深度学习记事簿</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/statics/logo.svg">
    <meta name="description" content="这里包含了我从入门到依然在入门的过程中接触到的大部分知识。翻翻目录，也许能找到有用的">
    <meta name="keywords" content="Akasaki,Deep learning,Machine learning,工具箱,工具箱的深度学习记事簿,Akasaki的深度学习记事簿">
    
    <link rel="preload" href="/assets/css/0.styles.71478383.css" as="style"><link rel="preload" href="/assets/js/app.579bc41f.js" as="script"><link rel="preload" href="/assets/js/2.024d806c.js" as="script"><link rel="preload" href="/assets/js/71.2aac9633.js" as="script"><link rel="prefetch" href="/assets/js/10.4c442f97.js"><link rel="prefetch" href="/assets/js/11.5da9b736.js"><link rel="prefetch" href="/assets/js/12.f101e6ce.js"><link rel="prefetch" href="/assets/js/13.f58a5ded.js"><link rel="prefetch" href="/assets/js/14.269eb641.js"><link rel="prefetch" href="/assets/js/15.40d2c0cf.js"><link rel="prefetch" href="/assets/js/16.882eb06c.js"><link rel="prefetch" href="/assets/js/17.4851e27a.js"><link rel="prefetch" href="/assets/js/18.8b83e144.js"><link rel="prefetch" href="/assets/js/19.c8730111.js"><link rel="prefetch" href="/assets/js/20.19d1cbe1.js"><link rel="prefetch" href="/assets/js/21.a79aa63f.js"><link rel="prefetch" href="/assets/js/22.7b8ded85.js"><link rel="prefetch" href="/assets/js/23.a7b93b05.js"><link rel="prefetch" href="/assets/js/24.a20d4bb7.js"><link rel="prefetch" href="/assets/js/25.4deeaec9.js"><link rel="prefetch" href="/assets/js/26.631fe133.js"><link rel="prefetch" href="/assets/js/27.ba05f0b5.js"><link rel="prefetch" href="/assets/js/28.ea88ddc3.js"><link rel="prefetch" href="/assets/js/29.54076f26.js"><link rel="prefetch" href="/assets/js/3.736cdea2.js"><link rel="prefetch" href="/assets/js/30.1bb315fb.js"><link rel="prefetch" href="/assets/js/31.0ac58d90.js"><link rel="prefetch" href="/assets/js/32.947e4e92.js"><link rel="prefetch" href="/assets/js/33.436c3bb6.js"><link rel="prefetch" href="/assets/js/34.7da1a08f.js"><link rel="prefetch" href="/assets/js/35.e1805606.js"><link rel="prefetch" href="/assets/js/36.14a21cbe.js"><link rel="prefetch" href="/assets/js/37.9d95c874.js"><link rel="prefetch" href="/assets/js/38.ed00ea11.js"><link rel="prefetch" href="/assets/js/39.8c9ed3d7.js"><link rel="prefetch" href="/assets/js/4.99c371bb.js"><link rel="prefetch" href="/assets/js/40.3acf80a1.js"><link rel="prefetch" href="/assets/js/41.68ec6bb9.js"><link rel="prefetch" href="/assets/js/42.8d291817.js"><link rel="prefetch" href="/assets/js/43.04b88cf3.js"><link rel="prefetch" href="/assets/js/44.d3d09b19.js"><link rel="prefetch" href="/assets/js/45.bdc277c6.js"><link rel="prefetch" href="/assets/js/46.1c9a3c14.js"><link rel="prefetch" href="/assets/js/47.475cdb5e.js"><link rel="prefetch" href="/assets/js/48.c5f2409a.js"><link rel="prefetch" href="/assets/js/49.1d13c570.js"><link rel="prefetch" href="/assets/js/5.a24d6838.js"><link rel="prefetch" href="/assets/js/50.b4bea273.js"><link rel="prefetch" href="/assets/js/51.b2425485.js"><link rel="prefetch" href="/assets/js/52.5b562e31.js"><link rel="prefetch" href="/assets/js/53.9db7815d.js"><link rel="prefetch" href="/assets/js/54.ed61c281.js"><link rel="prefetch" href="/assets/js/55.40015417.js"><link rel="prefetch" href="/assets/js/56.d3c74b1f.js"><link rel="prefetch" href="/assets/js/57.2c302e4a.js"><link rel="prefetch" href="/assets/js/58.a20caa6b.js"><link rel="prefetch" href="/assets/js/59.ca9c2a02.js"><link rel="prefetch" href="/assets/js/6.813c1476.js"><link rel="prefetch" href="/assets/js/60.c5c2e28f.js"><link rel="prefetch" href="/assets/js/61.634fe042.js"><link rel="prefetch" href="/assets/js/62.71d03150.js"><link rel="prefetch" href="/assets/js/63.997741ce.js"><link rel="prefetch" href="/assets/js/64.5486b729.js"><link rel="prefetch" href="/assets/js/65.5bf55bed.js"><link rel="prefetch" href="/assets/js/66.f24d51b5.js"><link rel="prefetch" href="/assets/js/67.531749c3.js"><link rel="prefetch" href="/assets/js/68.52e6d9d2.js"><link rel="prefetch" href="/assets/js/69.a2cae568.js"><link rel="prefetch" href="/assets/js/7.b1278ca1.js"><link rel="prefetch" href="/assets/js/70.e524a3a2.js"><link rel="prefetch" href="/assets/js/72.8e26c8e0.js"><link rel="prefetch" href="/assets/js/73.a9172e83.js"><link rel="prefetch" href="/assets/js/74.e67ca143.js"><link rel="prefetch" href="/assets/js/8.9d3b4527.js"><link rel="prefetch" href="/assets/js/9.f1f6f0e7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.71478383.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">工具箱的深度学习记事簿</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  View on Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/VisualDust" target="_blank" rel="noopener noreferrer" class="nav-link external">
  工具箱
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  View on Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/VisualDust" target="_blank" rel="noopener noreferrer" class="nav-link external">
  工具箱
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第零章：在开始之前</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章上：HelloWorld</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章下：深度学习基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章上：卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章下：经典卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章上：谈一些计算机视觉方向</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章下：一些计算机视觉任务</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录：永远是你的好朋友</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第五章：Playground</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第-1章：TensorFlow编程策略</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第-2章：数字信号处理（DSP）</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>魔法部日志（又名论文阅读日志）</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/unlimited-paper-works/[1]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs.html" class="sidebar-link">The Devil is in the Decoder: Classification, Regression and GANs</a></li><li><a href="/unlimited-paper-works/[2]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey.html" class="sidebar-link">Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey</a></li><li><a href="/unlimited-paper-works/[3]Progressive-Semantic-Segmentation.html" class="sidebar-link">Progressive Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[4]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation.html" class="sidebar-link">Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li><a href="/unlimited-paper-works/[5]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection.html" class="sidebar-link">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li><a href="/unlimited-paper-works/[6]DeepLab-Semantic-Image-Segmentation-with-Deep-Convolutional-Nets-Atrous-Convolution-and-Fully-Connected-CRFs.html" class="active sidebar-link">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/unlimited-paper-works/[7]Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation.html" class="sidebar-link">Rethinking Atrous Convolution for Semantic Image Segmentation</a></li><li><a href="/unlimited-paper-works/[8]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation.html" class="sidebar-link">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[9]Dynamic-Neural-Networks-A-Survey.html" class="sidebar-link">Dynamic Neural Networks: A Survey</a></li><li><a href="/unlimited-paper-works/[10]Feature-Pyramid-Networks-for-Object-Detection.html" class="sidebar-link">Feature Pyramid Networks for Object Detection</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="deeplab-semantic-image-segmentation-with-deep-convolutional-nets-atrous-convolution-and-fully-connected-crfs"><a href="#deeplab-semantic-image-segmentation-with-deep-convolutional-nets-atrous-convolution-and-fully-connected-crfs" class="header-anchor">#</a> DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</h1> <h3 id="这篇笔记的写作者是visualdust。"><a href="#这篇笔记的写作者是visualdust。" class="header-anchor">#</a> 这篇笔记的写作者是<a href="https://github.com/visualDust" target="_blank" rel="noopener noreferrer">VisualDust<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</h3> <p>原论文：<a href="https://arxiv.org/pdf/1606.00915.pdf" target="_blank" rel="noopener noreferrer">Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>在之前的语义分割网络中，分割结果往往比较粗糙，原因主要有两个，一是因为池化导致丢失信息，二是没有利用标签之间的概率关系，针对这两点，作者提出了针对性的改进。首先使用<strong>空洞卷积（Atrous Convolution）</strong>，避免池化带来的信息损失，然后使用<strong>条件随机场（CRF）</strong>，进一步优化分割精度。阅读这篇论文应关注的重点问题是：</p> <ul><li>空洞卷积</li> <li>条件随机场</li></ul> <blockquote><p>In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed &quot;DeepLab&quot; system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7% mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.</p></blockquote> <hr> <p>空洞卷积的主要作用是在增大感受野的同时，不增加参数数量，而且VGG中提出的多个小卷积核代替大卷积核的方法，只能使感受野线性增长，而多个空洞卷积串联，可以实现指数增长。</p> <p>关于条件随机长，简单来讲就是每个像素点作为节点，像素与像素间的关系作为边，即构成了一个条件随机场。通过二元势函数描述像素点与像素点之间的关系，鼓励相似像素分配相同的标签，而相差较大的像素分配不同标签，而这个“距离”的定义与颜色值和实际相对距离有关。所以这样CRF能够使图片在分割的边界出取得比较好的效果。</p> <p>咳咳，还没有开始写</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新时间:</span> <span class="time">5/11/2021, 6:22:54 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/unlimited-paper-works/[5]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection.html" class="prev">
        HLA-Face Joint High-Low Adaptation for Low Light Face Detection
      </a></span> <span class="next"><a href="/unlimited-paper-works/[7]Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation.html">
        Rethinking Atrous Convolution for Semantic Image Segmentation
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.579bc41f.js" defer></script><script src="/assets/js/2.024d806c.js" defer></script><script src="/assets/js/71.2aac9633.js" defer></script>
  </body>
</html>
